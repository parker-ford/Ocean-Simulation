#include "../Includes/common.cginc"
#include "../Includes/complex.cginc"

#pragma kernel CS_HorzontalStepIFFT
#pragma kernel CS_VerticalStepIFFT
#pragma kernel CS_PostProcess

//TODO: Figure out how to change this dynamically
#define SIZE 512
#define LOG_SIZE 9

RWTexture2D<float4> _Displacement;
RWTexture2D<float4> _Target;
bool _Scale, _Permute;
uint _MapSize, _Step, _LogSize;

groupshared float4 fftGroupBuffer[2][SIZE];

void ButterflyValues(uint step, uint index, bool inverse, out uint2 indices, out float2 twiddle) {
    const float twoPi = 6.28318530718;
    uint b = SIZE >> (step + 1);
    uint w = b * (index / b);
    uint i = (w + index) % SIZE;
    sincos(-twoPi / SIZE * w, twiddle.y, twiddle.x);

    if(inverse) twiddle.y = -twiddle.y;
    indices = uint2(i, i + b);
}

float4 FFT(uint threadIndex, float4 input, bool inverse) {
    fftGroupBuffer[0][threadIndex] = input;
    GroupMemoryBarrierWithGroupSync();
    bool flag = false;

    [unroll]
    for (uint step = 0; step < LOG_SIZE; ++step) {
        uint2 inputsIndices;
        float2 twiddle;
        ButterflyValues(step, threadIndex, inverse, inputsIndices, twiddle);

        float4 v = fftGroupBuffer[flag][inputsIndices.y];
        fftGroupBuffer[!flag][threadIndex] = fftGroupBuffer[flag][inputsIndices.x] + float4(ComplexMult(twiddle, v.xy), ComplexMult(twiddle, v.zw));

        flag = !flag;
        GroupMemoryBarrierWithGroupSync();
    }

    return fftGroupBuffer[flag][threadIndex];
}

[numthreads(SIZE,1,1)]
void CS_HorzontalStepIFFT(uint3 id : SV_DispatchThreadID)
{
	_Target[id.xy] = FFT(id.x, _Target[id.xy], true);

}

[numthreads(SIZE,1,1)]
void CS_VerticalStepIFFT(uint3 id : SV_DispatchThreadID)
{
	_Target[id.yx] = FFT(id.x, _Target[id.yx], true);

}

[numthreads(8, 8, 1)]
void CS_PostProcess(uint3 id : SV_DispatchThreadID)
{
	float4 val = _Target[id.xy];
	if(_Scale){
		val /= (float)(SIZE);
	}
	if(_Permute){
		val *= 1.0 - 2.0 * ((id.x + id.y) % 2);
	}
    _Target[id.xy] = val;
}
